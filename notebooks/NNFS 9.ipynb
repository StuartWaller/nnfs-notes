{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9: Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Neuron Example\n",
    "- **backpropagation** is a widely used algorithm in training feedforward neural networks for supervised learning\n",
    "- in fitting a neural network, backpropagation computes the gradient of the loss function with respect to the weights of the network for a single input–output example, and does so efficiently \n",
    "---\n",
    "- now that we have an idea of how to measure the impact of variables in a function’s output, we can begin to write the code to calculate these partial derivatives and begin to see their role in minimizing our loss\n",
    "- before applying backpropagation to a complete neural network, let’s backpropagate the ReLU function for a single neuron and act as if our intention is to minimize the output for this single neuron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "6.0"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "# Forward pass\n",
    "x = [1.0, -2.0, 3.0]  # input values\n",
    "w = [-3.0, -1.0, 2.0]  # weights\n",
    "b = 1.0  # bias\n",
    "\n",
    "# Multiplying inputs by weights\n",
    "wx0 = x[0] * w[0]\n",
    "wx1 = x[1] * w[1]\n",
    "wx2 = x[2] * w[2]\n",
    "\n",
    "# Adding\n",
    "s = wx0 + wx1 + wx2 + b\n",
    "\n",
    "# ReLU\n",
    "y = max(s, 0)  # we already described that with ReLU activation function description\n",
    "y # partial derivative of ReLU function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the first order of business is to backpropagate our gradients by calculating partial derivatives with respect to each of our parameters and inputs\n",
    "- in the context of our neural network, this can be interpreted as $relufunction(sum(weights * inputs)+bias)$, in which we will apply the chain rule\n",
    "- **let's work backwards with our single neuron, starting with the actual output (ReLU function)**\n",
    "- the output function, which is a ReLU function, doesn’t have a subsequent function’s partial derivatives to be multiplied by\n",
    "- so in this case, we just need to calculate the partial derivative for the ReLU function\n",
    "- recall the partial derivative for ReLU is 1 if the input is greater than 0, otherwise it's 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "dy = (1 if s > 0 else 0) \n",
    "dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **moving backwards through our neural network, the function that precedes the activation function is the sum of the weighted inputs and the bias**\n",
    "- this means we want to calculate the partial derivative of the sum function (derivative for a sum is 1) and then use the chain rule to multiply this value by the partial derivative of the subsequent function (which is the ReLU function)\n",
    "- we will call this result $dy$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwx0 = 1 * dy # derivative with respect to weighted input x\n",
    "dwx1 = 1 * dy\n",
    "dwx2 = 1 * dy\n",
    "db = 1 * dy # derivative with respect to bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **continuing backward, the function that comes before the sum is the multiplication of weights and inputs**\n",
    "- recall that the partial derivative of $f$ with respect to $x$ equals $y$ and the partial derivative of $f$ with respect to $y$ equals $x$\n",
    "- we can now apply this and the chain rule to calculate partial derivatives of $weights * bias$ multiplication operations with respect to its arguments (weights and biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx0 = w[0] * dwx0 # input\n",
    "dw0 = x[0] * dwx0 # weight\n",
    "dx1 = w[1] * dwx1\n",
    "dw1 = x[1] * dwx1\n",
    "dx2 = w[2] * dwx2\n",
    "dw2 = x[2] * dwx2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we are working backwards by taking the ReLU function's derivative, then taking the summing operation’s derivative, and multiplying both, and so on\n",
    "- again, this process is called backpropagation using the chain rule\n",
    "- as the name implies, the gradients of the resulting output function are passed back through the neural network\n",
    "---\n",
    "- at this point, we finally have the partial derivatives for the weights and the bias\n",
    "- we have everything we need to minimize the output of this neuron \n",
    "- for example, we can print the partial derivatives for each weight and the bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1.0 -2.0 3.0 1.0\n"
    }
   ],
   "source": [
    "print(dw0, dw1, dw2, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- full code thus far for forward and backward passing a single neuron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "6.0\n1.0 -2.0 3.0 1.0\n"
    }
   ],
   "source": [
    "# Forward pass\n",
    "x = [1.0, -2.0, 3.0]  # input values\n",
    "w = [-3.0, -1.0, 2.0]  # weights\n",
    "b = 1.0  # bias\n",
    "\n",
    "# Multiplying inputs by weights\n",
    "wx0 = x[0] * w[0]\n",
    "wx1 = x[1] * w[1]\n",
    "wx2 = x[2] * w[2]\n",
    "\n",
    "# Adding\n",
    "s = wx0 + wx1 + wx2 + b\n",
    "\n",
    "# ReLU\n",
    "y = max(s, 0)  # we already described that with ReLU activation function description\n",
    "print(y)\n",
    "\n",
    "# Backward pass\n",
    "dy = (1 if s > 0 else 0)  # derivative on ReLU activation function\n",
    "\n",
    "dwx0 = 1 * dy \n",
    "dwx1 = 1 * dy\n",
    "dwx2 = 1 * dy\n",
    "db = 1 * dy\n",
    "\n",
    "dx0 = w[0] * dwx0  \n",
    "dw0 = x[0] * dwx0\n",
    "dx1 = w[1] * dwx1\n",
    "dw1 = x[1] * dwx1\n",
    "dx2 = w[2] * dwx2\n",
    "dw2 = x[2] * dwx2\n",
    "\n",
    "print(dw0, dw1, dw2, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we can apply the chain rule here to calculate partial derivatives of the loss function with respect to the weights and input values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1.0 -2.0 3.0\n"
    }
   ],
   "source": [
    "dw0 = (1 if s > 0 else 0) * x[0]\n",
    "dw1 = (1 if s > 0 else 0) * x[1]\n",
    "dw2 = (1 if s > 0 else 0) * x[2]\n",
    "dx0 = (1 if s > 0 else 0) * w[0]\n",
    "dx1 = (1 if s > 0 else 0) * w[1]\n",
    "dx2 = (1 if s > 0 else 0) * w[2]\n",
    "\n",
    "print(dw0, dw1, dw2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- all together, the partial derivatives above combined into a vector make up our gradients\n",
    "- our gradients could be represented with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[-3.0, -1.0, 2.0] [1.0, -2.0, 3.0] 1\n"
    }
   ],
   "source": [
    "dx = [dx0, dx1, dx2]  # gradients on inputs\n",
    "dw = [dw0, dw1, dw2]  # gradients on weights\n",
    "print(dx, dw, db) # gradient on bias... just 1 bias here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- continuing with our single neuron example, with the goal of minimizing the output, we now can apply these gradients to our weights\n",
    "- for example, our current weights and bias are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[-3.0, -1.0, 2.0] 1.0\n"
    }
   ],
   "source": [
    "print(w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we can then apply a fraction of the gradients to these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[-3.001, -0.998, 1.997] 0.999\n"
    }
   ],
   "source": [
    "w[0] += -0.001 * dw[0]\n",
    "w[1] += -0.001 * dw[1]\n",
    "w[2] += -0.001 * dw[2]\n",
    "b += -0.001 * db\n",
    "\n",
    "print(w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we’ve slightly changed our weights and bias to intelligently decrease the output\n",
    "- we can see the effects of our tweaks on the output by doing another forward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "5.985\n"
    }
   ],
   "source": [
    "# Multiplying inputs by weights\n",
    "wx0 = x[0] * w[0]\n",
    "wx1 = x[1] * w[1]\n",
    "wx2 = x[2] * w[2]\n",
    "\n",
    "# Adding\n",
    "s = wx0 + wx1 + wx2 + b\n",
    "\n",
    "# ReLU\n",
    "y = max(s, 0) \n",
    "print(y) # used to yield 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we’ve successfully decreased this neuron’s output from 6.000 to 5.985"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entire Layer Example\n",
    "- as we’ve done before, we’ll apply the one-neuron example to the list of samples and expand it to an entire layer of neurons\n",
    "- to begin, let’s set a list of 3 feature sets (also called samples) for input, where each feature set consists of 4 features\n",
    "- for this example, our network will consist of a single hidden layer containing 3 neurons\n",
    "- as before, we’re going to use NumPy to apply the dot product to inputs and weights, and then add biases \n",
    "- to do that, we will transpose the weights in order to match the input dimension and transpose the biases to produce a column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 0.1985  0.5005 -0.2615]\n [ 0.7903 -0.9147 -0.2797]\n [-0.5053  0.2537  0.1647]\n [ 0.9963 -0.5017  0.8663]]\n[[1.997 2.998 0.497]]\n"
    }
   ],
   "source": [
    "# From previous toy example, modified for a purpose of backpropagation\n",
    "import numpy as np\n",
    "\n",
    "inputs = np.array([[1, 2, 3, 2.5], [2., 5., -1., 2], [-1.5, 2.7, 3.3, -0.8]])  # now we have 3 samples (feature sets) of data\n",
    "weights = np.array([[0.2, 0.8, -0.5, 1], # now we have 3 sets of weights - one set for each neuron\n",
    "                    [0.5, -0.91, 0.26, -0.5],\n",
    "                    [-0.26, -0.27, 0.17, 0.87]]).T # transpose all weights to match input distribution\n",
    "biases = np.array([[2], [3], [0.5]]).T  # one bias for each neuron\n",
    "\n",
    "# Forward pass\n",
    "layer_outputs = np.dot(inputs, weights) + biases  # forward pass thru Dense layer\n",
    "relu_outputs = np.maximum(0, layer_outputs)  # forward pass thru ReLU activation\n",
    "\n",
    "# Let's optimize and test backpropagation here\n",
    "# ReLU activation\n",
    "relu_dvalues = np.ones(relu_outputs.shape) # simulates derivative with respect to input values from next layer passed to current layer during backpropagation\n",
    "relu_dvalues[layer_outputs <= 0] = 0\n",
    "drelu = relu_dvalues\n",
    "\n",
    "# Dense layer\n",
    "dinputs = np.dot(drelu, weights.T)  # dinputs - multiply by weights\n",
    "dweights = np.dot(inputs.T, drelu)  # dweights - multiply by inputs\n",
    "dbiases = np.sum(drelu, axis=0, keepdims=True)  # sbiases - sum values, do this over samples (first axis), keepdims as this by default will produce a plain list - we discussed this earlier\n",
    "\n",
    "# Update parameters\n",
    "weights += -0.001 * dweights\n",
    "biases += -0.001 * dbiases\n",
    "\n",
    "print(weights) # successfully decreased\n",
    "print(biases) # successfully decreased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- in this code, we replaced plain Python functions with NumPy functions, created example data, calculated forward and backward passes, and updated the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Neural Network Code\n",
    "- now let's update the Dense layer and ReLU activation code with a backwards method (for backpropagation)\n",
    "- during the `forward()` method for our `Layer_Dense()` class, we will wwant to remember what the inputs were so we can use them for backpropagation\n",
    "- this can be easily implemented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Dense:    \n",
    "    ...\n",
    "    def forward(self, inputs):\n",
    "        ...\n",
    "        self.inputs = inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- next, we will add our backward pass (backpropagation) code that we developed previously \n",
    "- we'll call this the `backward()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Dense:\n",
    " \n",
    "    ...  \n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Gradients on parameters\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        # Gradient on values\n",
    "        self.dvalues = np.dot(dvalues, self.weights.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we will do the same for our `Activation_ReLU()` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU activation\n",
    "class Activation_ReLU:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Since we need to modify the original variable, \n",
    "        # let's make a copy of the values first\n",
    "        self.dvalues = dvalues.copy()\n",
    "\n",
    "        # Zero gradient where input values where negative \n",
    "        self.dvalues[self.inputs <= 0] = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- at this point, we’ve covered everything we need in order to perform backpropagation except for the derivative of the Softmax activation function and the derivative of the Cross-entropy loss function\n",
    "---\n",
    "- our method of doing this will be similar to our previous backpropagation examples\n",
    "- we will only calculate the derivative in the cross-entropy loss class, because we’re using one combined derivative formula for both the softmax activation and the cross-entropy loss\n",
    "- we can combine these operations as we assume that cross-entropy loss is always going to be used together with the softmax activation function in the output layer \n",
    "- all we need to do is add a `backward()` method to our `Activation_Softmax()` class, and all this backward method needs to do is store the derivative values for the backpropagation we’re going to apply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Softmax:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, \n",
    "                                            keepdims=True))\n",
    "        # normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1, \n",
    "                                            keepdims=True)\n",
    "\n",
    "        self.output = probabilities\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        self.dvalues = dvalues.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- next, we’ll add the code to calculate gradients of the loss function with the `Loss_CategoricalCrossentropy()` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-entropy loss\n",
    "class Loss_CategoricalCrossentropy:\n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        # Number of samples in a batch\n",
    "        samples = y_pred.shape[0]\n",
    "\n",
    "        # Probabilities for target values - \n",
    "        # only if categorical labels\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_pred = y_pred[range(samples), y_true]\n",
    "\n",
    "        # Losses\n",
    "        negative_log_likelihoods = -np.log(y_pred)\n",
    "\n",
    "        # Mask values - only for one-hot encoded labels\n",
    "        if len(y_true.shape) == 2:\n",
    "            negative_log_likelihoods *= y_true\n",
    "\n",
    "        # Overall loss\n",
    "        data_loss = np.sum(negative_log_likelihoods) / samples\n",
    "        return data_loss\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        samples = dvalues.shape[0]\n",
    "\n",
    "        self.dvalues = dvalues.copy()  # Copy so we can safely modify\n",
    "        self.dvalues[range(samples), y_true] -= 1\n",
    "        self.dvalues = self.dvalues / samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0.33333333 0.33333333 0.33333333]\n [0.33333317 0.33333318 0.33333364]\n [0.33333289 0.33333292 0.3333342 ]\n [0.33333259 0.33333264 0.33333477]\n [0.33333233 0.33333239 0.33333528]]\nloss: 1.0986104615465142\nacc: 0.34\n[[ 1.57663575e-04  7.83685868e-05  4.73243939e-05]\n [ 1.81610390e-04  1.10455707e-05 -3.30962973e-05]]\n[[-3.60553684e-04  9.66122221e-05 -1.03671511e-04]]\n[[ 5.44109554e-05  1.07411413e-04 -1.61822369e-04]\n [-4.07913528e-05 -7.16780945e-05  1.12469447e-04]\n [-5.30112970e-05  8.58172904e-05 -3.28059934e-05]]\n[[-1.06521079e-05 -9.44490453e-06  2.00970125e-05]]\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "# Our sample dataset\n",
    "def create_data(n, k):\n",
    "    X = np.zeros((n*k, 2))  # data matrix (each row = single example)\n",
    "    y = np.zeros(n*k, dtype='uint8')  # class labels\n",
    "    for j in range(k):\n",
    "        ix = range(n*j, n*(j+1))\n",
    "        r = np.linspace(0.0, 1, n)  # radius\n",
    "        t = np.linspace(j*4, (j+1)*4, n) + np.random.randn(n)*0.2  # theta\n",
    "        X[ix] = np.c_[r*np.sin(t*2.5), r*np.cos(t*2.5)]\n",
    "        y[ix] = j\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Dense layer\n",
    "class Layer_Dense:\n",
    "\n",
    "    # Layer initialization\n",
    "    def __init__(self, inputs, neurons):\n",
    "        # Initialize weights and biases\n",
    "        self.weights = 0.01 * np.random.randn(inputs, neurons)\n",
    "        self.biases = np.zeros((1, neurons))\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from input ones, weights and biases\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Gradients on parameters\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        # Gradient on values\n",
    "        self.dvalues = np.dot(dvalues, self.weights.T)\n",
    "\n",
    "\n",
    "# ReLU activation\n",
    "class Activation_ReLU:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from input ones\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Since we need to modify original variable, \n",
    "        # let's make a copy of values first\n",
    "        self.dvalues = dvalues.copy()\n",
    "\n",
    "        # Zero gradient where input values were negative \n",
    "        self.dvalues[self.inputs <= 0] = 0 \n",
    "\n",
    "\n",
    "# Softmax activation\n",
    "class Activation_Softmax:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        # normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "\n",
    "        self.output = probabilities\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        self.dvalues = dvalues.copy()\n",
    "\n",
    "\n",
    "# Cross-entropy loss\n",
    "class Loss_CategoricalCrossentropy:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        # Number of samples in a batch\n",
    "        samples = y_pred.shape[0]\n",
    "\n",
    "        # Probabilities for target values - only if categorical labels\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_pred = y_pred[range(samples), y_true]\n",
    "\n",
    "        # Losses\n",
    "        negative_log_likelihoods = -np.log(y_pred)\n",
    "\n",
    "        # Mask values - only for one-hot encoded labels\n",
    "        if len(y_true.shape) == 2:\n",
    "            negative_log_likelihoods *= y_true\n",
    "\n",
    "        # Overall loss\n",
    "        data_loss = np.sum(negative_log_likelihoods) / samples\n",
    "        return data_loss\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        samples = dvalues.shape[0]\n",
    "\n",
    "        self.dvalues = dvalues.copy()  # Copy so we can safely modify\n",
    "        self.dvalues[range(samples), y_true] -= 1\n",
    "        self.dvalues = self.dvalues / samples\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "X, y = create_data(100, 3)\n",
    "\n",
    "# Create Dense layer with 2 input features and 3 output values\n",
    "dense1 = Layer_Dense(2, 3)  # first dense layer, 2 inputs (each sample has 2 features), 3 outputs\n",
    "\n",
    "# Create ReLU activation (to be used with Dense layer):\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Create second Dense layer with 3 input features (as we take output of previous layer here) and 3 output values (output values)\n",
    "dense2 = Layer_Dense(3, 3)  # second dense layer, 3 inputs, 3 outputs\n",
    "\n",
    "# Create Softmax activation (to be used with Dense layer):\n",
    "activation2 = Activation_Softmax()\n",
    "\n",
    "# Create loss function\n",
    "loss_function = Loss_CategoricalCrossentropy()\n",
    "\n",
    "# Make a forward pass of our training data thru this layer\n",
    "dense1.forward(X)\n",
    "\n",
    "# Make a forward pass thru activation function - we take output of previous layer here\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "# Make a forward pass thru second Dense layer - it takes outputs of activation function of first layer as inputs\n",
    "dense2.forward(activation1.output)\n",
    "\n",
    "# Make a forward pass thru activation function - we take output of previous layer here\n",
    "activation2.forward(dense2.output)\n",
    "\n",
    "# Let's see output of the first few samples:\n",
    "print(activation2.output[:5])\n",
    "\n",
    "# Calculate loss from output of activation2 (softmax activation)\n",
    "loss = loss_function.forward(activation2.output, y)\n",
    "\n",
    "# Print loss value\n",
    "print('loss:', loss)\n",
    "\n",
    "# Calculate accuracy from output of activation2 and targets\n",
    "predictions = np.argmax(activation2.output, axis=1)  # calculate values along first axis\n",
    "accuracy = np.mean(predictions==y)\n",
    "\n",
    "print('acc:', accuracy)\n",
    "\n",
    "# Backward pass\n",
    "loss_function.backward(activation2.output, y)\n",
    "activation2.backward(loss_function.dvalues)\n",
    "dense2.backward(activation2.dvalues)\n",
    "activation1.backward(dense2.dvalues)\n",
    "dense1.backward(activation1.dvalues)\n",
    "\n",
    "# Print gradients\n",
    "print(dense1.dweights)\n",
    "print(dense1.dbiases)\n",
    "print(dense2.dweights)\n",
    "print(dense2.dbiases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- at this point, thanks to gradients and backpropagation using the chain rule, we’ll be able to adjust the weights and biases in accordance with the objective of lowering our loss\n",
    "- this process of adjusting weights and biases using gradients with the objective of decreasing loss is the job of the **optimizer**, which is the subject of the next chapter"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}